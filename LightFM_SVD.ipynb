{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/backup/lib/python3.11/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightfm.cross_validation import random_train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"shopping_behavior_updated.csv\")\n",
    "data['Customer ID'] = data['Customer ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create age group\n",
    "data['Age Group'] = pd.cut(data['Age'], bins=[0, 25, 35, 50, 100], labels=['<25', '25-35', '35-50', '>50'])\n",
    "# Review Rating -> Postive or Negative\n",
    "data['weighted_liked'] = data['Review Rating'].apply(lambda x: 3.0 if x >= 4.0 else 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create feature for user and item\n",
    "user_features = [f\"Age Group:{group}\" for group in data['Age Group'].unique()] + \\\n",
    "                [f\"Gender:{gender}\" for gender in data['Gender'].unique()] + \\\n",
    "                [f\"Previous Purchases:{purchases}\" for purchases in data['Previous Purchases'].unique()]  # Thêm Previous Purchases\n",
    "\n",
    "item_features = list(data['Category'].unique()) + \\\n",
    "                list(data['Season'].unique()) + \\\n",
    "                list(data['Color'].unique()) + \\\n",
    "                [f\"Discount:{disc}\" for disc in data['Discount Applied'].unique()] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = Dataset()\n",
    "dataset.fit(\n",
    "    data['Customer ID'], \n",
    "    data['Item Purchased'], \n",
    "    user_features=user_features, \n",
    "    item_features=item_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions_matrix, _) = dataset.build_interactions(\n",
    "    [(x['Customer ID'], x['Item Purchased'], x['weighted_liked']) for _, x in data.iterrows()]\n",
    ")\n",
    "\n",
    "user_features_matrix = dataset.build_user_features(\n",
    "    [(x['Customer ID'], [f\"Age Group:{x['Age Group']}\", f\"Gender:{x['Gender']}\", \n",
    "                         f\"Previous Purchases:{x['Previous Purchases']}\"])  # Thêm Previous Purchases\n",
    "     for _, x in data.iterrows()]\n",
    ")\n",
    "\n",
    "item_features_matrix = dataset.build_item_features(\n",
    "    [(x['Item Purchased'], [x['Category'], x['Season'], x['Color'], f\"Discount:{x['Discount Applied']}\"]) \n",
    "     for _, x in data.iterrows()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions, test_interactions = random_train_test_split(interactions_matrix, test_percentage=0.1, random_state=np.random.RandomState(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: warp, Components: 50, Epochs: 10, AUC: 0.5117\n",
      "Loss: warp, Components: 50, Epochs: 30, AUC: 0.7930\n",
      "Loss: warp, Components: 50, Epochs: 50, AUC: 0.8214\n",
      "Loss: warp, Components: 100, Epochs: 10, AUC: 0.5354\n",
      "Loss: warp, Components: 100, Epochs: 30, AUC: 0.8155\n",
      "Loss: warp, Components: 100, Epochs: 50, AUC: 0.8219\n",
      "Loss: warp, Components: 200, Epochs: 10, AUC: 0.5136\n",
      "Loss: warp, Components: 200, Epochs: 30, AUC: 0.8156\n",
      "Loss: warp, Components: 200, Epochs: 50, AUC: 0.8223\n",
      "Loss: warp, Components: 300, Epochs: 10, AUC: 0.5186\n",
      "Loss: warp, Components: 300, Epochs: 30, AUC: 0.8113\n",
      "Loss: warp, Components: 300, Epochs: 50, AUC: 0.8226\n",
      "Loss: bpr, Components: 50, Epochs: 10, AUC: 0.4988\n",
      "Loss: bpr, Components: 50, Epochs: 30, AUC: 0.5053\n",
      "Loss: bpr, Components: 50, Epochs: 50, AUC: 0.5235\n",
      "Loss: bpr, Components: 100, Epochs: 10, AUC: 0.5040\n",
      "Loss: bpr, Components: 100, Epochs: 30, AUC: 0.5029\n",
      "Loss: bpr, Components: 100, Epochs: 50, AUC: 0.5386\n",
      "Loss: bpr, Components: 200, Epochs: 10, AUC: 0.5024\n",
      "Loss: bpr, Components: 200, Epochs: 30, AUC: 0.5029\n",
      "Loss: bpr, Components: 200, Epochs: 50, AUC: 0.5217\n",
      "Loss: bpr, Components: 300, Epochs: 10, AUC: 0.5000\n",
      "Loss: bpr, Components: 300, Epochs: 30, AUC: 0.4980\n",
      "Loss: bpr, Components: 300, Epochs: 50, AUC: 0.5212\n",
      "Loss: logistic, Components: 50, Epochs: 10, AUC: 0.5034\n",
      "Loss: logistic, Components: 50, Epochs: 30, AUC: 0.5034\n",
      "Loss: logistic, Components: 50, Epochs: 50, AUC: 0.5034\n",
      "Loss: logistic, Components: 100, Epochs: 10, AUC: 0.5034\n",
      "Loss: logistic, Components: 100, Epochs: 30, AUC: 0.5034\n",
      "Loss: logistic, Components: 100, Epochs: 50, AUC: 0.5034\n",
      "Loss: logistic, Components: 200, Epochs: 10, AUC: 0.5034\n",
      "Loss: logistic, Components: 200, Epochs: 30, AUC: 0.5034\n",
      "Loss: logistic, Components: 200, Epochs: 50, AUC: 0.5034\n",
      "Loss: logistic, Components: 300, Epochs: 10, AUC: 0.5034\n",
      "Loss: logistic, Components: 300, Epochs: 30, AUC: 0.5034\n",
      "Loss: logistic, Components: 300, Epochs: 50, AUC: 0.5034\n",
      "Loss: warp-kos, Components: 50, Epochs: 10, AUC: 0.5096\n",
      "Loss: warp-kos, Components: 50, Epochs: 30, AUC: 0.7786\n",
      "Loss: warp-kos, Components: 50, Epochs: 50, AUC: 0.8225\n",
      "Loss: warp-kos, Components: 100, Epochs: 10, AUC: 0.5157\n",
      "Loss: warp-kos, Components: 100, Epochs: 30, AUC: 0.8103\n",
      "Loss: warp-kos, Components: 100, Epochs: 50, AUC: 0.8221\n",
      "Loss: warp-kos, Components: 200, Epochs: 10, AUC: 0.5153\n",
      "Loss: warp-kos, Components: 200, Epochs: 30, AUC: 0.8137\n",
      "Loss: warp-kos, Components: 200, Epochs: 50, AUC: 0.8239\n",
      "Loss: warp-kos, Components: 300, Epochs: 10, AUC: 0.5222\n",
      "Loss: warp-kos, Components: 300, Epochs: 30, AUC: 0.8136\n",
      "Loss: warp-kos, Components: 300, Epochs: 50, AUC: 0.8234\n",
      "Cấu hình tốt nhất: Loss = warp-kos, Components = 200, Epochs = 50\n",
      "AUC cao nhất: 0.8239\n"
     ]
    }
   ],
   "source": [
    "best_auc = 0\n",
    "best_config = None\n",
    "for loss in ['warp', 'bpr', 'logistic', 'warp-kos']:\n",
    "    for components in [50, 100, 200, 300]:\n",
    "        for epochs in [10, 30, 50]:\n",
    "            # Khởi tạo mô hình\n",
    "            model = LightFM(loss=loss, no_components=components, random_state=42)\n",
    "            \n",
    "            # Huấn luyện\n",
    "            model.fit(train_interactions, user_features=user_features_matrix, \n",
    "                      item_features=item_features_matrix, epochs=epochs, num_threads=4)\n",
    "            \n",
    "            # Tính AUC\n",
    "            test_auc = auc_score(model, interactions_matrix, \n",
    "                                 user_features=user_features_matrix, \n",
    "                                 item_features=item_features_matrix, \n",
    "                                 num_threads=4).mean()\n",
    "            \n",
    "            print(f\"Loss: {loss}, Components: {components}, Epochs: {epochs}, AUC: {test_auc:.4f}\")\n",
    "            \n",
    "            # Cập nhật cấu hình tốt nhất\n",
    "            if test_auc > best_auc:\n",
    "                best_auc = test_auc\n",
    "                best_config = (loss, components, epochs)\n",
    "\n",
    "# Hiển thị kết quả tốt nhất\n",
    "print(f\"Cấu hình tốt nhất: Loss = {best_config[0]}, Components = {best_config[1]}, Epochs = {best_config[2]}\")\n",
    "print(f\"AUC cao nhất: {best_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_items_with_scores(clicked_product, customer_id, model, dataset, user_features, item_features, data, top_n=10):\n",
    "    \"\"\"\n",
    "    Gợi ý sản phẩm tương tự dựa trên Item, kèm điểm số.\n",
    "    \"\"\"\n",
    "    # Lấy chỉ số ánh xạ của sản phẩm đã chọn\n",
    "    item_index = dataset.mapping()[2][clicked_product]\n",
    "    \n",
    "    # Lấy chỉ số ánh xạ của khách hàng\n",
    "    user_index = dataset.mapping()[0][customer_id]\n",
    "    \n",
    "    # Dự đoán điểm số cho tất cả sản phẩm dựa trên khách hàng và sản phẩm\n",
    "    item_ids = np.arange(len(dataset.mapping()[2]))  # Danh sách tất cả sản phẩm\n",
    "    scores = model.predict(\n",
    "        user_ids=user_index,\n",
    "        item_ids=item_ids,\n",
    "        user_features=user_features,\n",
    "        item_features=item_features\n",
    "    )\n",
    "    \n",
    "    # Tìm sản phẩm tương tự sản phẩm đã chọn (embedding)\n",
    "    _, item_embeddings = model.get_item_representations(item_features)\n",
    "    similarities = np.dot(item_embeddings, item_embeddings[item_index])\n",
    "    \n",
    "    # Lọc và sắp xếp sản phẩm theo điểm số giảm dần\n",
    "    item_mapping = {v: k for k, v in dataset.mapping()[2].items()}\n",
    "    scored_items = [\n",
    "        (item_mapping[i], similarities[i], scores[i]) \n",
    "        for i in np.argsort(-similarities) if item_mapping[i] != clicked_product\n",
    "    ][:top_n]\n",
    "    \n",
    "    # Gắn thêm thông tin sản phẩm\n",
    "    recommendations = [\n",
    "        (item, data[data['Item Purchased'] == item]['Category'].values[0], similarity, score)\n",
    "        for item, similarity, score in scored_items\n",
    "    ]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gợi ý sản phẩm dựa trên người dùng tương tự (User-based) kèm điểm số\n",
    "def recommend_similar_users_with_scores(customer_id, model, dataset, user_features, item_features, data, top_n=10):\n",
    "    \"\"\"\n",
    "    Gợi ý sản phẩm dựa trên người dùng tương tự, kèm điểm số.\n",
    "    \"\"\"\n",
    "    # Lấy chỉ số ánh xạ của người dùng\n",
    "    user_index = dataset.mapping()[0][customer_id]\n",
    "    \n",
    "    # Lấy embedding người dùng\n",
    "    _, user_embeddings = model.get_user_representations(user_features)\n",
    "    similarities = np.dot(user_embeddings, user_embeddings[user_index])\n",
    "    \n",
    "    # Tìm người dùng tương tự\n",
    "    user_mapping = {v: k for k, v in dataset.mapping()[0].items()}\n",
    "    top_users = [\n",
    "        user_mapping[i] for i in np.argsort(-similarities) \n",
    "        if user_mapping[i] != customer_id\n",
    "    ][:top_n]\n",
    "    \n",
    "    # Dự đoán điểm số cho tất cả sản phẩm\n",
    "    item_ids = np.arange(len(dataset.mapping()[2]))\n",
    "    scores = model.predict(\n",
    "        user_ids=user_index,\n",
    "        item_ids=item_ids,\n",
    "        user_features=user_features,\n",
    "        item_features=item_features\n",
    "    ) \n",
    "    \n",
    "    # Gợi ý sản phẩm từ những người dùng tương tự\n",
    "    item_mapping = {v: k for k, v in dataset.mapping()[2].items()}\n",
    "    recommendations = []\n",
    "    for similar_user in top_users:\n",
    "        similar_user_index = dataset.mapping()[0][similar_user]\n",
    "        similar_scores = model.predict(\n",
    "            user_ids=similar_user_index,\n",
    "            item_ids=item_ids,\n",
    "            user_features=user_features,\n",
    "            item_features=item_features\n",
    "        )\n",
    "        recommended_items = [\n",
    "            (item_mapping[i], scores[i]) for i in np.argsort(-similar_scores)\n",
    "        ][:top_n]\n",
    "        recommendations.extend(recommended_items)\n",
    "    \n",
    "    # Loại bỏ trùng lặp và sắp xếp theo điểm số\n",
    "    recommendations = list(set(recommendations))\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_recommendations(clicked_product, customer_id, model, dataset, user_features, item_features, data, top_n=10):\n",
    "    \"\"\"\n",
    "    Gợi ý sản phẩm tổng hợp, tính trung bình giữa Item-based và User-based recommendations,\n",
    "    sau đó sắp xếp theo giá trị trung bình (average score + similarity), đảm bảo giá trị dương.\n",
    "    \"\"\"\n",
    "    # Gợi ý dựa trên sản phẩm (Item-based)\n",
    "    item_recommendations = recommend_similar_items_with_scores(\n",
    "        clicked_product, customer_id, model, dataset, user_features, item_features, data, top_n=top_n\n",
    "    )\n",
    "    \n",
    "    # Chuyển danh sách Item-based thành dict {item: (category, similarity, score)}\n",
    "    item_recommend_dict = {\n",
    "        item: (data[data['Item Purchased'] == item]['Category'].values[0], similarity, score)\n",
    "        for item, _, similarity, score in item_recommendations\n",
    "    }\n",
    "    \n",
    "    # Gợi ý dựa trên người dùng tương tự (User-based)\n",
    "    user_recommendations = recommend_similar_users_with_scores(\n",
    "        customer_id, model, dataset, user_features, item_features, data, top_n=top_n\n",
    "    )\n",
    "    \n",
    "    # Kết hợp gợi ý User-based vào dict\n",
    "    for item, score in user_recommendations:\n",
    "        category = data[data['Item Purchased'] == item]['Category'].values[0]\n",
    "        if item in item_recommend_dict:\n",
    "            # Tính trung bình similarity và score\n",
    "            old_similarity = item_recommend_dict[item][1] if item_recommend_dict[item][1] is not None else 0\n",
    "            old_score = item_recommend_dict[item][2]\n",
    "            new_similarity = (old_similarity + 0) / 2 if old_similarity else None\n",
    "            avg_score = (old_score + score) / 2\n",
    "            item_recommend_dict[item] = (category, new_similarity, avg_score)\n",
    "        else:\n",
    "            # Thêm mục mới từ User-based\n",
    "            item_recommend_dict[item] = (category, None, score)  # Similarity là None vì từ User-based\n",
    "    \n",
    "    # Dịch chuyển giá trị similarity và score để dương hết\n",
    "    all_similarities = [sim for _, (_, sim, _) in item_recommend_dict.items() if sim is not None]\n",
    "    all_scores = [score for _, (_, _, score) in item_recommend_dict.items()]\n",
    "    \n",
    "    min_similarity = min(all_similarities) if all_similarities else 0\n",
    "    min_score = min(all_scores)\n",
    "    \n",
    "    for item in item_recommend_dict:\n",
    "        category, similarity, score = item_recommend_dict[item]\n",
    "        similarity = similarity - min_similarity if similarity is not None else None\n",
    "        score = score - min_score\n",
    "        item_recommend_dict[item] = (category, similarity, score)\n",
    "    \n",
    "    # Sắp xếp các sản phẩm theo score trung bình giảm dần\n",
    "    sorted_recommendations = sorted(item_recommend_dict.items(), key=lambda x: x[1][2], reverse=True)\n",
    "    \n",
    "    # Chuyển thành danh sách kết quả\n",
    "    final_recommendations = [\n",
    "        (item, category, similarity, score)\n",
    "        for item, (category, similarity, score) in sorted_recommendations[:top_n]\n",
    "    ]\n",
    "    \n",
    "    return final_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sản phẩm 'Blouse' đã được nhấn.\n",
      "\n",
      "Gợi ý sản phẩm (ưu tiên dựa trên sản phẩm, bổ sung từ người dùng tương tự nếu cần):\n",
      "  Skirt (Category: Clothing) - Similarity: 16.36 - Score: 1.49\n",
      "  Shirt (Category: Clothing) - Similarity: 16.32 - Score: 1.48\n",
      "  Socks (Category: Clothing) - Similarity: 16.30 - Score: 1.48\n",
      "  Pants (Category: Clothing) - Similarity: 16.28 - Score: 1.48\n",
      "  Dress (Category: Clothing) - Similarity: 16.28 - Score: 1.48\n",
      "  Sweater (Category: Clothing) - Similarity: 16.32 - Score: 1.48\n",
      "  Hoodie (Category: Clothing) - Similarity: 16.29 - Score: 1.47\n",
      "  Shorts (Category: Clothing) - Similarity: 16.29 - Score: 1.47\n",
      "  Blouse (Category: Clothing) - Similarity: N/A - Score: 1.47\n",
      "  T-shirt (Category: Clothing) - Similarity: 16.28 - Score: 1.47\n",
      "  Jeans (Category: Clothing) - Similarity: 16.22 - Score: 1.46\n",
      "  Shoes (Category: Footwear) - Similarity: 4.30 - Score: 0.27\n",
      "  Sandals (Category: Footwear) - Similarity: 4.29 - Score: 0.26\n",
      "  Sneakers (Category: Footwear) - Similarity: 4.27 - Score: 0.25\n",
      "  Sunglasses (Category: Accessories) - Similarity: 0.10 - Score: 0.25\n",
      "  Boots (Category: Footwear) - Similarity: 4.23 - Score: 0.24\n",
      "  Jewelry (Category: Accessories) - Similarity: 0.07 - Score: 0.24\n",
      "  Handbag (Category: Accessories) - Similarity: 0.08 - Score: 0.23\n",
      "  Belt (Category: Accessories) - Similarity: 0.06 - Score: 0.23\n",
      "  Hat (Category: Accessories) - Similarity: 0.00 - Score: 0.23\n",
      "  Gloves (Category: Accessories) - Similarity: 0.15 - Score: 0.23\n",
      "  Backpack (Category: Accessories) - Similarity: 0.06 - Score: 0.23\n",
      "  Scarf (Category: Accessories) - Similarity: 0.04 - Score: 0.22\n",
      "  Jacket (Category: Outerwear) - Similarity: 2.56 - Score: 0.01\n",
      "  Coat (Category: Outerwear) - Similarity: 2.57 - Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Nhập sản phẩm được nhấn và ID người dùng từ người dùng\n",
    "clicked_product = input(\"Nhập sản phẩm mà bạn đã bấm (clicked product): \")\n",
    "customer_id = input(\"Nhập ID người dùng (customer ID): \")\n",
    "\n",
    "# Gợi ý tổng hợp\n",
    "combined_recommendation_list = combined_recommendations(\n",
    "    clicked_product, customer_id, model, dataset, user_features_matrix, item_features_matrix, data, top_n=50\n",
    ")\n",
    "\n",
    "# Hiển thị kết quả\n",
    "print(f\"\\nSản phẩm '{clicked_product}' đã được nhấn.\")\n",
    "print(\"\\nGợi ý sản phẩm (ưu tiên dựa trên sản phẩm, bổ sung từ người dùng tương tự nếu cần):\")\n",
    "for item, category, similarity, score in combined_recommendation_list:\n",
    "    sim_text = f\"Similarity: {similarity:.2f}\" if similarity is not None else \"Similarity: N/A\"\n",
    "    score_text = f\"Score: {score:.2f}\" if score is not None else \"Score: N/A\"\n",
    "    print(f\"  {item} (Category: {category}) - {sim_text} - {score_text}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Dripy Sales.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "backup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
